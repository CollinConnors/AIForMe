# On the Shoulders of Giants
![Lecture 0: On the Shoulder of Giants](assets/images/lecture0-header.png)

??? slides "Lecture Slides"
    <div style="width:100%; height:800px;position:relative;padding-top:56.25%;height:0;overflow:hidden;">
      <iframe
        src ="https://docs.google.com/file/d/106cyU4NjbW4L687pJKaFL8PKaqTjYir3/preview" 
        style="position:absolute;top:0;left:0;width:100%;height:100%;border:0;"
        allow="autoplay"
        allowfullscreen>
      </iframe>
    </div>

    [Download the slides (PPTX)](assets/slides/lecture0.pptx)

??? recording "Lecture recording"
    <div style="width:100%; height:600px;">
      <!-- YouTube example -->
      <iframe
        src="https://www.youtube.com/embed/VIDEO_ID"
        title="Lecture 1 Recording"
        style="width:100%; height:100%; border:0;"
        allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
        allowfullscreen>
      </iframe>
    </div>
    <!-- Or Google Drive video:
    <iframe src="https://drive.google.com/file/d/DRIVE_VIDEO_ID/preview"
            style="width:100%; height:600px; border:0;" allow="autoplay" allowfullscreen></iframe>
    -->

??? homework "HW problems"
    # Lecture 0 Homework Problems

    ## 0.1: Known vs. Approved AI Tools

    **Background:**  
    The university classifies AI tools based on risk, data governance, and academic integrity considerations. Some tools are widely used and recognized as “known,” but are not approved for general academic use, while others are officially approved and supported by the university.

    **Instructions:**  
    Select one AI tool classified as a “known” tool by the university (for example, ChatGPT) and one university-approved AI tool (such as Microsoft Copilot, Google Gemini, NotebookLM, or Adobe Firefly). Create two to three neutral prompts and submit the same prompts to both tools. Compare the responses in terms of quality, clarity, tone, transparency, and any visible safeguards or warnings.

    Prepare a short report that includes:

      - The tools selected and why you chose them  
      - The prompts used  
      - A comparison of the outputs  
      - An explanation of why the university may classify one tool as “known” rather than “approved”  

    Include screenshots of the prompts and outputs where applicable.

    ---

    ## 0.2: Investigating a Banned AI Tool

    **Background:**  
    Some AI tools are explicitly banned by the university due to heightened risks related to data privacy, security, licensing, or academic integrity. Understanding these risks is critical for responsible AI use in an academic environment.

    **Instructions:**  
    Select one AI tool listed as “banned” by the university. Conduct research only on the tool; do not use or interact with it. Investigate what the tool does, who operates it, how it handles user data, and the risks it may pose in an academic setting.

    Prepare a short report that includes:

      - A brief overview of the tool and its advertised capabilities  
      - Identified risks or concerns (e.g., privacy, security, academic misconduct)  
      - A reasoned explanation for why the university may have chosen to ban the tool  

    Support your analysis with credible sources and include citations where appropriate.

    ---

    ## 0.3: Comparing University-Approved AI Tools

    **Background:**  
    The university provides access to several approved AI tools—Microsoft Copilot, Google Gemini, NotebookLM, and Adobe Firefly—each designed for different types of tasks and use cases. Understanding the strengths and limitations of each tool helps you choose the most appropriate AI resource for a given academic or professional task.

    **Instructions:**  
    Review and use each of the university-approved AI tools: Microsoft Copilot, Google Gemini, NotebookLM, and Adobe Firefly. Explore the core features and intended use cases of each tool, focusing on how they support learning, research, content creation, and productivity.

    Prepare a short report that includes:

      - A brief description of the primary features of each tool  
      - A comparison of how each tool handles tasks such as writing assistance, research support, summarization, or content creation  
      - Specific examples of scenarios where you would choose one tool over the others (you may not use the examples provided—come up with your own)  
      - A reflection on how using the correct tool can improve efficiency while staying within university AI usage policies  

    Include screenshots demonstrating key features or example interactions with each tool where applicable.

    ---

    ## 0.4: Data Privacy and AI Tools

    **Background:**  
    AI tools differ significantly in how they collect, store, and use user data. The university evaluates these practices when determining whether a tool is approved, known but not approved, or banned, with student data privacy and regulatory compliance being key considerations.

    **Instructions:**  
    Select one university-approved AI tool, one “known” but not approved AI tool, and one banned AI tool. Review the publicly available privacy policy and terms of use for each tool. Analyze what information the tool collects, how user inputs and outputs may be logged or retained, and whether data may be shared with third parties or used for model training.

    Prepare a short report that includes:

      - A brief summary of each tool and its classification (approved, known, or banned)  
      - The types of data you provide to the tool (e.g., prompts, files, metadata, account information)  
      - What data may be logged, stored, reused, or shared according to the privacy policy  
      - A comparison of privacy risks across the three tools  
      - Practical steps a student can take to improve their privacy when using AI tools (e.g., data minimization, anonymization, tool selection)

    Support your analysis with citations to the privacy policies reviewed and include screenshots or excerpts where applicable.

    ---

    ## 0.5: AI Ethics and Disclosure

    **Background:**  
    As AI tools become more capable and accessible, questions of ethics, transparency, and disclosure have become increasingly important. The appropriate use of AI varies by context, and failing to disclose AI assistance can raise concerns related to trust, accountability, and fairness.

    **Instructions:**  
    Reflect on the ethical implications of using AI tools in different contexts, including academic settings, business or professional environments, and personal life. Consider situations where using AI may be inappropriate, misleading, or harmful, even if it is technically allowed. Additionally, evaluate whether—and how—individuals should disclose their use of AI.

    Prepare a short report that addresses the following:

      - Examples of situations where using AI would be unethical in school, even if the tool is approved  
      - Examples of situations where AI use may be unethical or misleading in business or professional contexts  
      - Examples from everyday life where AI use could create ethical concerns (e.g., relationships, decision-making, or public discourse)  
      - Your position on AI disclosure requirements, including:

        - When disclosure should be mandatory, optional, or unnecessary  
        - Who should be responsible for disclosure (student, employee, organization)  
        - What meaningful disclosure should look like (e.g., a statement, citation, or disclaimer)

    Support your arguments with clear reasoning and, where appropriate, references to ethical principles, professional standards, or real-world examples.

    ---

    ## 0.6: AI Policies Across the Curriculum

    **Background:**  
    AI usage policies can vary widely across courses, departments, and institutions. Some classes explicitly permit AI tools, others restrict their use, and many have no formal policy at all.

    **Instructions:**  
    Select one course you are currently taking (excluding this class). Review the syllabus, course website, or other official materials to determine whether the course has an explicit AI usage policy. If no policy exists, note that explicitly.

    Prepare a short report that addresses the following:
    
      - Whether the selected course has an AI policy and, if so, a brief summary of what it allows or restricts  
      - If no policy exists, how AI usage is currently implied or handled in practice  
      - From the perspective of the professor, what concerns or goals should shape an AI policy (e.g., learning outcomes, assessment integrity, workload)  
      - From the perspective of a university administrator, what risks or obligations should influence policy decisions (e.g., academic integrity, legal compliance, equity)  
      - From your perspective as a student, what an effective and fair AI policy should

    Conclude by proposing a clear, concise AI policy for the selected course.

??? references "References"
    - [On the Shoulder of Giants](https://digitallibrary.hsp.org/Detail/objects/9792s)
    - [University of Miami AI](https://ai.it.miami.edu/)
    - [University of Miami Approved AI Tools](https://ai.it.miami.edu/ai-tools/index.html)
    - [University of Miami Known AI Tools](https://ai.it.miami.edu/ai-tools/known-ai-tools/index.html)
    - [University of Miami AI Projects](https://ai.it.miami.edu/ai-projects/index.html)
    - [University of Miami Library Resources](https://guides.library.miami.edu/newspapers)
    - [Microsoft CoPilot](https://copilot.microsoft.com/)
    - [Google Gemini](https://gemini.google.com/)
    - [NotebookLM](https://notebooklm.google.com/)
    - [Adobe Firefly](https://firefly.adobe.com/)

